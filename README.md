# ğŸ“° BlockchainX - Automated News & Twitter Bot

[![Daily News Collection](https://github.com/YOUR_USERNAME/blockchainX/actions/workflows/daily-news.yml/badge.svg)](https://github.com/YOUR_USERNAME/blockchainX/actions/workflows/daily-news.yml)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> Automated blockchain news collection with AI-powered translation and Twitter distribution. Enriches your GitHub contribution graph while building an automated social media presence.

ğŸ“š **Documentation**: [Quick Start](docs/QUICKSTART.md) | [Setup](docs/SETUP.md) | [Twitter](docs/TWITTER_SETUP.md) | [Architecture](docs/PROJECT_OVERVIEW.md)

## ğŸ¯ Project Purpose

This project automatically:
- ğŸ“¡ Scrapes blockchain news from CoinDesk (3x daily)
- ğŸ¤– Translates headlines with AI (OpenAI/DeepL/Google)
- ğŸ¦ Posts to Twitter automatically
- ğŸ’¾ Stores articles in organized Markdown files
- ğŸ“Š Enriches your GitHub contribution graph
- ğŸ”„ Maintains a historical news archive

## âœ¨ Features

### News Collection
- **ğŸ” Automated Scraping**: Runs 3x daily (00:00, 08:00, 16:00 UTC)
- **ğŸ“° Full Article Content**: Complete text, not just headlines
- **ğŸ”„ Smart Deduplication**: Avoids collecting duplicate articles
- **ğŸ›¡ï¸ Error Handling**: Graceful fallbacks and retry logic
- **ğŸ’¾ Space Efficient**: ~54-270 MB/year, well within GitHub limits

### Twitter Integration (Optional)
- **ğŸ¤– AI Translation**: OpenAI GPT, DeepL, or Google Translate
- **ï¿½ Auto-Posting**: 3-10 tweets/day with smart rate limiting
- **ï¿½ Tweet Optimization**: Professional formatting with hashtags
- **ğŸ”’ Secure**: All API keys in GitHub Secrets
- **ğŸ’° Affordable**: ~$0.60/month with OpenAI

### Technical
- **ğŸš€ Zero Maintenance**: GitHub Actions automation
- **ğŸ”Œ Extensible**: Easy to add new sources
- **ï¿½ Clean Output**: Professional Markdown format
- **âš™ï¸ Configurable**: Customizable schedules and settings

## ğŸ“‚ Project Structure

```
blockchainX/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily-news.yml       # GitHub Actions workflow
â”œâ”€â”€ data/
â”‚   â””â”€â”€ YYYY-MM-DD/              # Date-organized folders
â”‚       â””â”€â”€ coindesk.md          # Daily headlines
â”œâ”€â”€ scraper.py                   # Main scraping script
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore                   # Git ignore rules
â””â”€â”€ README.md                    # This file
```

## ğŸš€ Quick Start

### 1. Fork/Clone This Repository

```bash
git clone https://github.com/YOUR_USERNAME/blockchainX.git
cd blockchainX
```

### 2. Install Dependencies (for local testing)

```bash
pip install -r requirements.txt
```

### 3. Test Locally

```bash
python scraper.py
```

This will create a `data/YYYY-MM-DD/coindesk.md` file with today's headlines.

### 4. Configure GitHub Secrets

Go to your repository on GitHub: **Settings** â†’ **Secrets and variables** â†’ **Actions** â†’ **New repository secret**

Add the following secrets:

| Secret Name | Description | Required |
|-------------|-------------|----------|
| `PAT_TOKEN` | Personal Access Token with `repo` scope | âš ï¸ Optional* |
| `COMMITTER_NAME` | Your name for git commits | âš ï¸ Optional** |
| `COMMITTER_EMAIL` | Your email for git commits | âš ï¸ Optional** |

**Notes:**
- *`PAT_TOKEN`: Only required if you want commits to trigger other workflows. Otherwise, the default `GITHUB_TOKEN` works fine.
- **`COMMITTER_NAME` and `COMMITTER_EMAIL`: If not set, defaults to your GitHub username and noreply email.

#### Creating a Personal Access Token (PAT)

1. Go to GitHub **Settings** â†’ **Developer settings** â†’ **Personal access tokens** â†’ **Tokens (classic)**
2. Click **Generate new token** â†’ **Generate new token (classic)**
3. Give it a descriptive name: `blockchainX-workflow`
4. Select scope: `repo` (Full control of private repositories)
5. Click **Generate token** and copy it
6. Add it as `PAT_TOKEN` secret in your repository

### 5. Enable GitHub Actions

1. Go to the **Actions** tab in your repository
2. Enable workflows if prompted
3. The workflow will run automatically on schedule
4. You can also trigger it manually: **Actions** â†’ **Daily Blockchain News Collection** â†’ **Run workflow**

## ğŸ“Š GitHub Contribution Graph Enhancement

The workflow runs 3 times daily by default, creating a natural activity pattern. For even richer contributions:

1. Go to **Actions** â†’ **Daily Blockchain News Collection** â†’ **Run workflow**
2. Enable **"Generate multiple commits throughout the day"** option
3. This creates 3-4 commits spread across the day

**Important**: Don't overdo this! GitHub may flag suspicious patterns. The default 3 scheduled runs is recommended.

## ğŸ› ï¸ Technical Highlights

### Robust Web Scraping
- **Full Article Content**: Fetches complete article text, not just headlines
- **Smart Deduplication**: Tracks collected articles to avoid repeats
- **Multiple fallback strategies**: for HTML parsing
- **User-agent rotation support**
- **Retry logic** with exponential backoff
- **Graceful degradation** if source is unavailable

### Clean Architecture
- Object-oriented design with `NewsSource` base class
- Easy to extend to new sources (CoinTelegraph, Decrypt, etc.)
- Separation of concerns: scraping, storage, workflow
- History tracking system to prevent duplicate collections

### Production-Ready
- Comprehensive error handling
- Logging and status reporting
- Git push retry logic
- Timestamp tracking for audit trails
- Automatic cleanup of old history data

## ï¿½ Storage & Maintenance

### Storage Space Analysis

**Current Configuration:**
- **Articles per run**: 5 articles
- **Runs per day**: 3 times (00:00, 08:00, 16:00 UTC)
- **Total daily**: 15 articles maximum

**Storage Estimates:**

| Timeframe | With Full Articles | With Summaries Only |
|-----------|-------------------|---------------------|
| Per article | 10-50 KB | ~0.5 KB |
| Per day | 150-750 KB | ~7.5 KB |
| Per year | 54-270 MB | ~2.7 MB |
| 10 years | 540 MB - 2.7 GB | ~27 MB |

### GitHub Repository Limits

- âœ… **Single file**: < 100 MB (safe)
- âœ… **Repository recommended**: < 1 GB
- âš ï¸ **Repository hard limit**: 5 GB
- âœ… **Single push**: < 2 GB

### Risk Assessment

**Conclusion: âœ… SAFE**

With full article content, you'll use approximately **54-270 MB per year**, which is well within GitHub's limits. After 10 years, the repository would be around 2.7 GB at maximum, still under the 5 GB hard limit.

### Maintenance Recommendations

**Monthly:**
- Review workflow logs for errors
- Check data quality in recent files
- Update dependencies: `pip install --upgrade -r requirements.txt`

**Yearly:**
- Archive old data to a separate branch
- Create a release tag for the year
- Consider cleaning up data older than 2 years

**Optional Data Cleanup:**

```bash
# Archive old data (example: move 2023 data to archive branch)
git checkout -b archive-2023
git mv data/2023-* archive/
git commit -m "Archive 2023 data"
git push origin archive-2023

# Return to main branch
git checkout main
git rm -r data/2023-*
git commit -m "Clean up 2023 data (archived)"
git push origin main
```

### History File Management

The `.history.json` file automatically cleans up entries older than 30 days to prevent it from growing indefinitely. This is handled by the scraper automatically.

## ï¿½ğŸ”§ Customization

### Adding New News Sources

The system is designed to support **multiple languages** including English, Chinese, and other languages.

#### English Source Example

Edit `scraper.py` and add a new class:

```python
class CoinTelegraphSource(NewsSource):
    """CoinTelegraph news scraper"""
    
    def __init__(self):
        super().__init__("CoinTelegraph", "https://cointelegraph.com")
    
    def extract_headlines(self, max_articles: int = 20) -> List[Dict[str, str]]:
        # Implement extraction logic
        html = self.fetch_page(self.url)
        # Parse HTML and return headlines
        return headlines
```

#### Chinese Source Example (ä¸­æ–‡ç½‘ç«™ç¤ºä¾‹)

```python
class JinseSource(NewsSource):
    """é‡‘è‰²è´¢ç» news scraper"""
    
    def __init__(self):
        super().__init__("JinSe", "https://www.jinse.com")
    
    def extract_headlines(self, max_articles: int = 20) -> List[Dict[str, str]]:
        # å®ç°æå–é€»è¾‘
        html = self.fetch_page(self.url)
        # è§£æHTMLå¹¶è¿”å›å¤´æ¡
        return headlines
```

#### Multilingual Source Example (å¤šè¯­è¨€æ”¯æŒ)

```python
class BlockBeatsSource(NewsSource):
    """BlockBeats - Supports Chinese and English"""
    
    def __init__(self, language='zh'):
        url = "https://www.theblockbeats.info" if language == 'zh' else "https://en.theblockbeats.info"
        name = "BlockBeats (å¾‹åŠ¨)" if language == 'zh' else "BlockBeats"
        super().__init__(name, url)
        self.language = language
```

#### Register Your Sources

In `main()`, add to sources list:

```python
sources = [
    CoinDeskSource(),           # English
    CoinTelegraphSource(),      # English
    JinseSource(),              # Chinese (ä¸­æ–‡)
    BlockBeatsSource('zh'),     # Chinese
    BlockBeatsSource('en'),     # English
]
```

#### Supported Source Ideas

**English Sources:**
- The Block: https://www.theblock.co
- Decrypt: https://decrypt.co
- Bitcoin Magazine: https://bitcoinmagazine.com
- Forkast: https://forkast.news

**Chinese Sources (ä¸­æ–‡æ¥æº):**
- é‡‘è‰²è´¢ç» (JinSe): https://www.jinse.com
- å·´æ¯”ç‰¹ (8btc): https://www.8btc.com
- é“¾é—» (ChainNews): https://www.chainnews.com
- PANews: https://www.panewslab.com
- å¸å£° (CoinVoice): https://www.coinvoice.cn
- å¾‹åŠ¨ (BlockBeats): https://www.theblockbeats.info

**Note:** Full implementation templates are provided in `scraper.py` file comments.

### Changing Schedule

Edit `.github/workflows/daily-news.yml`:

```yaml
schedule:
  - cron: '0 9 * * *'   # 9 AM UTC
  - cron: '0 21 * * *'  # 9 PM UTC
```

Use [crontab.guru](https://crontab.guru/) to help create cron expressions.

### Customizing Output Format

Edit the `save_to_markdown()` function in `scraper.py` to change the Markdown format.

## ğŸ“ˆ Data Format

Each daily file (`data/YYYY-MM-DD/coindesk.md`) contains:

```markdown
# CoinDesk - Top Headlines

**Date:** 2025-11-04
**Source:** [CoinDesk](https://www.coindesk.com)

---

## 1. [Headline Title]

[Summary or excerpt from the article...]

**Read more:** [https://www.coindesk.com/article-url](https://www.coindesk.com/article-url)

---

*Collected at: 2025-11-04 08:00:00 UTC*
```

## ğŸ› Troubleshooting

### Workflow Not Running

- Check if Actions are enabled: **Settings** â†’ **Actions** â†’ **General**
- Ensure the workflow file is in `.github/workflows/` directory
- Check the **Actions** tab for error messages

### No Commits Appearing

- Verify git configuration secrets are set correctly
- Check workflow logs for push errors
- Ensure `PAT_TOKEN` has correct permissions if using custom token

### Script Fails to Scrape

- Website structure may have changed
- Check workflow logs for specific error messages
- Test locally: `python scraper.py`
- Consider adding additional fallback strategies

### Rate Limiting

If you're being rate-limited:
- Reduce frequency in workflow schedule
- Add more delay between requests in `scraper.py`
- Use proxy rotation (advanced)

## ğŸ“œ License

MIT License - feel free to use this for your own projects!

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:
- Add new news sources
- Improve scraping reliability
- Enhance Markdown formatting
- Report bugs or suggest features

## ğŸ“š Documentation

- **[Quick Start](docs/QUICKSTART.md)** - Get started in 5 minutes âš¡
- **[Setup Guide](docs/SETUP.md)** - Scraper setup and GitHub Actions
- **[Twitter Integration](docs/TWITTER_SETUP.md)** - AI translation and auto-posting
- **[Technical Overview](docs/PROJECT_OVERVIEW.md)** - Architecture details

## ï¿½ğŸ“ Support

If you encounter issues:

1. Check the [Issues](https://github.com/YOUR_USERNAME/YOUR_REPO/issues) page
2. Review workflow logs in the **Actions** tab
3. Test locally with `python scraper.py`
4. See [Troubleshooting Guide](docs/SETUP.md#troubleshooting)
5. Open a new issue with detailed information

## ğŸŒŸ Star This Repository

If you find this useful, please consider starring the repository!

---

**Built with â¤ï¸ for the blockchain community**

*Last updated: November 2025*
